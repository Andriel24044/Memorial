{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46daa146",
   "metadata": {},
   "source": [
    "## 4.2 Stop right now, thank you very much\n",
    "\n",
    "Nomes: Andressa Cristine M. Costa e Andriel Vinicius Martins da Silva\n",
    "\n",
    "### 1. Objetivo: \n",
    "Implemente uma estratégia de Parada Antecipada (Early Stopping) no\n",
    "processo de treino da rede neural feita em Python puro ou no processo de treino da rede\n",
    "neural feita em PyTorch.\n",
    "\n",
    "**Comentário:** esta não é para resolver com o módulo lightning.\n",
    "\n",
    "### 2. Early Stopping:\n",
    "\n",
    "A estratégia de Early Stopping consiste na implementação de um modo de parar o treinamento quando o desempenho do modelo para um determinado conjunto de dados de validação para de melhorar [1]. Esse tipo de estratégia é implementado para evitar o cenário de overfitting, que é quando o modelo se ajusta excessivamente aos dados de treino e acaba não ficando bom para prever os dados de validação. Assim, conseguiríamos melhorar o desempenho do modelo.\n",
    "\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"imgs/Early%20Stopping.webp\" alt=\"Early Stopping\" width=\"300\"/>\n",
    "    <figcaption>Figura 1 - Exemplo de plots de curva de aprendizado. [1]</figcaption>\n",
    "</div>\n",
    "\n",
    "A ideia principal é monitorar o desempenho do modelo durante o treinamento e parar de treinar quando as curvas de aprendizado entre os dados de validação e os dados de treino começam a divergir (a distância entre os respectivos pontos entre as duas curvas começa a aumentar).\n",
    "\n",
    "No caso da nossa implementação, essas curvas de aprendizado são plotadas em função da perda obtida para os dados de validação e os dados de treinamento. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136f5ec0",
   "metadata": {},
   "source": [
    "### 3. Implementação\n",
    "\n",
    "**I) Escolha de dados:** O dataset escolhido para a implementação desse código foi o `penguins` da biblioteca seaborn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13eae94c-96c0-4f39-9bb4-30d58cd93601",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e549fced",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sns.load_dataset('penguins').dropna() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615aeec1",
   "metadata": {},
   "source": [
    "A importação de dados foi conduzida normalmente com a implementação de um método dropna() para remover possíveis valores de NaN. Após isso, foi implementada uma normalização dos dados de entrada conforme sugestão do professor para tentar melhorar o desempenho do modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a340cde-9ba0-40cc-b793-ec69538e5c53",
   "metadata": {},
   "source": [
    "**II) Tratamento dos dados:** nessa etapa os dados foram normalizados via método `MinMaxScaler` da biblioteca `sklearn`, no qual converte os dados para um intevalo de 0 a 1.\n",
    "\n",
    "- Escolheu-se as seguintes **features** para o problema: `bill_length_mm, bill_depth_mm, flipper_length_mm`, sendo comprimento do bico, profundidade do bico e comprimento da nadadeira, todos em milímetros, respectivamente. E o **target** escolhido `body_mass_g`, se refere a massa corporal em gramas dos penguins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1557c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "features = df[[\"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\"]]\n",
    "\n",
    "normalizador = MinMaxScaler()\n",
    "\n",
    "normalizador.fit(features)\n",
    "\n",
    "features = normalizador.transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593d0996",
   "metadata": {},
   "source": [
    "Nessa etapa foi necessário consultar [2] para converter os dados de features para o formato correto para o uso com torch, convertendo de uma dataframe para um tensor e do formato float 64 para o 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74204fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.from_numpy(features.astype(np.float32))\n",
    "x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f554a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df[\"body_mass_g\"].values\n",
    "target = target.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b254e7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizador = MinMaxScaler()\n",
    "\n",
    "normalizador.fit(target)\n",
    "\n",
    "target = normalizador.transform(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468b9533",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.from_numpy(target.astype(np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd75b0fa-a568-4db8-b31e-daf22d5e8c83",
   "metadata": {},
   "source": [
    "**III) Criação da Rede Neural:** O trecho abaixo trata-se da criação da rede neural com a utilização da biblioteca `pyTorch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa37d1dd-b051-4ea8-999f-5e27d6ff0b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, num_dados_entrada, neuronios_c1, num_targets):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.camadas = nn.Sequential(\n",
    "            nn.Linear(num_dados_entrada, neuronios_c1),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(neuronios_c1, num_targets),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.camadas(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51141844-b8cb-45ed-af95-6a787e326c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_DADOS_DE_ENTRADA = 3  \n",
    "NUM_DADOS_DE_SAIDA = 1\n",
    "NEURONIOS_C1 = 121\n",
    "\n",
    "minha_mlp = MLP(\n",
    "    NUM_DADOS_DE_ENTRADA, NEURONIOS_C1, NUM_DADOS_DE_SAIDA\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccc6327-ff79-4713-9605-2df84ca820dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "TAXA_DE_APRENDIZADO = 0.003\n",
    "\n",
    "otimizador = optim.SGD(minha_mlp.parameters(), lr=TAXA_DE_APRENDIZADO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c077deb9-f488-4271-8099-feb973921401",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_perda = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf536a09-b85e-425b-9d45-bd0fd22a2c49",
   "metadata": {},
   "source": [
    "**IV) Split dos dados:** Divisão dos dados de testes, treino e validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6777cfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_20, y_train, y_20 = train_test_split(x, y, test_size=0.20, random_state=42)\n",
    "\n",
    "x_val, x_teste, y_val, y_teste = train_test_split(x_20, y_20, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ee1394-8a28-4570-99ae-7e23cddbe112",
   "metadata": {},
   "source": [
    "**V) Execução da Rede Neural** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fb847c-c737-45be-abcf-68f74ec2128f",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCAS = 100\n",
    "\n",
    "minha_mlp.train()\n",
    "\n",
    "fator_de_parada = 100\n",
    "\n",
    "melhora_minima = 0.01\n",
    "\n",
    "contador_de_parada = 0\n",
    "\n",
    "melhor_perda = float('inf')\n",
    "\n",
    "l_val = []\n",
    "l_train = []\n",
    "\n",
    "for epoca in range(NUM_EPOCAS):\n",
    "    # forward pass\n",
    "    y_pred = minha_mlp(x_train)\n",
    "\n",
    "    # zero grad\n",
    "    otimizador.zero_grad()\n",
    "\n",
    "    # loss\n",
    "    loss = fn_perda(y_train.view(-1, 1), y_pred.view(-1, 1))\n",
    "\n",
    "    # backpropagation\n",
    "    loss.backward()\n",
    "\n",
    "    # atualiza parâmetros\n",
    "    otimizador.step()\n",
    "\n",
    "    l_train.append(loss.item())\n",
    "\n",
    "    minha_mlp.eval()\n",
    "    \n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for x_v, y_v in zip(x_val, y_val.view(-1, 1)):\n",
    "            y_pred = minha_mlp(x_v)\n",
    "            val_loss += fn_perda(y_v, y_pred).item() #calcula a perda a partir da difereça entre o real e o predito\n",
    "\n",
    "    val_loss /= len(y_val)\n",
    "    l_val.append(val_loss)\n",
    "    minha_mlp.train()\n",
    "\n",
    "    if val_loss < melhor_perda - melhora_minima:\n",
    "        melhor_perda = val_loss\n",
    "        contador_de_parada = 0\n",
    "    else:\n",
    "        contador_de_parada += 1\n",
    "        if contador_de_parada == fator_de_parada:\n",
    "            print(f\"Parada antecipada na epoca: {epoca}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067ddb9c",
   "metadata": {},
   "source": [
    "### Implementação do Early Stopping\n",
    "\n",
    "```python \n",
    " minha_mlp.eval()\n",
    "    \n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for x_v, y_v in zip(x_val, y_val.view(-1, 1)):\n",
    "            y_pred = minha_mlp(x_v)\n",
    "            val_loss += fn_perda(y_v, y_pred).item()\n",
    "\n",
    "    val_loss /= len(y_val)\n",
    "    l_val.append(val_loss)\n",
    "    minha_mlp.train()\n",
    "\n",
    "    if val_loss < melhor_perda - melhora_minima:\n",
    "        melhor_perda = val_loss\n",
    "        contador_de_parada = 0\n",
    "    else:\n",
    "        contador_de_parada += 1\n",
    "        if contador_de_parada == fator_de_parada:\n",
    "            print(f\"Parada antecipada na epoca: {epoca}\")\n",
    "            break\n",
    "```\n",
    "\n",
    "O código acima traz a implementação do Early Stopping [1]. Primeiramente, alternando do modo de treino para o modo de teste e calculamos a função de perda para a predição da rede até o momento. Com esse valor de perda, observa-se a variação entre as perdas de treino e de validação; caso essa diferença seja maior do que nas iterações anteriores, o algoritmo encerra sua execução.\n",
    "\n",
    "Um fator de melhora mínima pode ser aplicado para indicar o quanto será necessário que o valor de perda seja reduzido em relação ao valor anterior. Além disso, há um contador de paradas, responsável por indicar quantas vezes o código ainda pode rodar após ser alcançado um valor de perda maior que o atual."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bce28ed-2b25-43d0-940a-74712d1c4544",
   "metadata": {},
   "source": [
    "**VI) Plotagem das perdas:** Foram reunidas as perdas durante as etapas de treino e validação para comparação via gráfico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45d95ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "x = list(range(0, len(l_val)))\n",
    "\n",
    "plt.plot(x, l_val, label = 'Perda de validação')\n",
    "plt.plot(x, l_train, label = 'Perda de treino')\n",
    "\n",
    "plt.title('Comparação entre perdas')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afefb78a-d1ee-43b0-b28c-923dd8b36b9a",
   "metadata": {},
   "source": [
    "O gráfico acima se comporta de forma um pouco diferente do esperado, de acordo com a imagem apresentada na introdução. Isso se deve ao fato de o dataset escolhido ser didático, contendo dados com uma correlação clara."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0766af9-4218-40bd-a475-f95c7b26de2e",
   "metadata": {},
   "source": [
    "**VII) Teste e calculo do RMSE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd19979-b174-4b77-9e47-c55888335602",
   "metadata": {},
   "outputs": [],
   "source": [
    "minha_mlp.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da26e10-4cde-43a1-a303-4c1430650be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    y_pred = minha_mlp(x_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658e3c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_teste = normalizador.inverse_transform(y_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667c3bcb-eb4f-4cf4-ad8b-42c19f54f1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = normalizador.inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df31c92-c794-4040-824d-4dc9aa908010",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "RMSE = mean_squared_error(y_teste, y_pred, squared=False)\n",
    "print(RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36929dc-c08e-45ea-bff7-6761d61afdf7",
   "metadata": {},
   "source": [
    "### 4. Conclusão\n",
    "Analisando o valor de RMSE obtido, percebe-se um resultado insatisfatório no que diz respeito à predição. Porém, isso ocorre devido às limitações do dataset escolhido e à falta de otimização dos hiperparâmetros. No entanto, considerando o objetivo principal — a aplicação do Early Stopping — o código apresentou o comportamento esperado, encerrando a execução assim que a taxa de aprendizado começou a divergir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65f71fe-ec17-4203-b899-13ef84544f2b",
   "metadata": {},
   "source": [
    "### 5. Referências\n",
    "\n",
    "[1]. CYBORG. What is Early Stopping in Deep Learning? - Cyborg - Medium. Disponível em: <https://cyborgcodes.medium.com/what-is-early-stopping-in-deep-learning-eeb1e710a3cf>.\n",
    "\n",
    "[2]‌. DSA, E. Capítulo 28 - Usando Early Stopping Para Definir o Número de Épocas de Treinamento - Deep Learning Book. Disponível em: <https://www.deeplearningbook.com.br/usando-early-stopping-para-definir-o-numero-de-epocas-de-treinamento/>.\n",
    "\n",
    "[3]. GEEKSFORGEEKS. Converting a Pandas DataFrame to a PyTorch Tensor. Disponível em: https://www.geeksforgeeks.org/converting-a-pandas-dataframe-to-a-pytorch-tensor/. Acesso em: 9 jun. 2025.\n",
    "\n",
    "[4]. STACK OVERFLOW. Convert numpy array type and values from float64 to float32. Disponível em: https://stackoverflow.com/questions/45955186/convert-numpy-array-type-and-values-from-float64-to-float32. Acesso em: 9 jun. 2025.\n",
    "\n",
    "[5]. train_test_split. Disponível em: <http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html>. Acesso em: 9 jun. 2025.\n",
    "\n",
    "[6].CASSAR, Daniel. [Material de sala de aula]. Redes Neurais e Algoritmos Genéticos, 2025, Ilum - Escola de Ciência."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ilumpy",
   "language": "python",
   "name": "ilumpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
